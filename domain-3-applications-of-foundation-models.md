# Domain 3: Applications of Foundation Models

[![Back to Main](https://img.shields.io/badge/‚Üê-Back%20to%20Main-blue?style=flat)](README.md)

## üìã Overview
This domain covers the practical applications of foundation models in various industries and use cases. Understanding these applications is crucial for leveraging AI/ML solutions on AWS effectively. **Weight: 28% of the exam.**

## üéØ Key Topics Covered

### 3.1: Describe design considerations for applications that use foundation models
Objectives:
- Identify selection criteria to choose pre-trained models (for example, cost,
modality, latency, multi-lingual, model size, model complexity,
customization, input/output length).
- Understand the effect of inference parameters on model responses (for
example, temperature, input/output length).
- Define Retrieval Augmented Generation (RAG) and describe its business
applications (for example, Amazon Bedrock, knowledge base).
- Identify AWS services that help store embeddings within vector databases
(for example, Amazon OpenSearch Service, Amazon Aurora, Amazon
Neptune, Amazon DocumentDB [with MongoDB compatibility], Amazon
RDS for PostgreSQL).
- Explain the cost tradeoffs of various approaches to foundation model
customization (for example, pre-training, fine-tuning, in-context learning,
RAG).
- Understand the role of agents in multi-step tasks (for example, Agents for
Amazon Bedrock).

#### Understand the effect of inference parameters on model responses
- **Temperature**: A parameter that controls the randomness of the model's output. Higher values (e.g., 0.8) result in more diverse and creative responses, while lower values (e.g., 0.2) produce more focused and deterministic outputs.
- **Input/Output Length**: The maximum number of tokens the model can process in a single request. Longer input lengths allow for more context, while output length determines how much text the model can generate in response.
- **Top-p (nucleus sampling)**: A parameter that controls the diversity of the model's output by limiting the selection of tokens to a subset with a cumulative probability above a certain threshold (p). This helps balance creativity and coherence in generated text.

### 3.2: Choose effective prompt engineering techniques
Objectives:
- Describe the concepts and constructs of prompt engineering (for example,
context, instruction, negative prompts, model latent space).
- Understand techniques for prompt engineering (for example, chain-ofthought, zero-shot, single-shot, few-shot, prompt templates).
- Understand the benefits and best practices for prompt engineering (for
example, response quality improvement, experimentation, guardrails,
discovery, specificity and concision, using multiple comments).
- Define potential risks and limitations of prompt engineering (for example,
exposure, poisoning, hijacking, jailbreaking).

#### Describe the concepts and constructs of prompt engineering
- **Input Data**: The information or content provided to the foundation model to generate a response.
- **Output Data**: The response or result generated by the foundation model based on the input data and prompt.
- **Context**: The background information or setting provided to the model to help it understand the task or generate relevant responses.
- **Instruction**: A clear and specific directive given to the model to guide its response or behavior.
- **Negative prompts**: Instructions that specify what the model should avoid or not include in its response.
- **Model latent space**: The high-dimensional space in which the model represents and processes information, capturing relationships and patterns learned during training.

#### Understand techniques for prompt engineering
- **Chain-of-thought**: This technique involves providing a model with a series of reasoning steps or a logical progression of ideas to guide it toward generating a more accurate and coherent response.
- **Zero-shot**: The zero-example request technique requires FMs to generate a response without providing explicit examples of the desired behavior, relying solely on their pre-training.
- **Single-shot**: This technique involves providing the model with a single example of the desired output format or behavior within the prompt itself to help guide its response.
- **Few-shot**: This technique involves providing the model with a few examples of the desired input-output pairs within the prompt. These examples guide the model to understand the pattern or format expected in its responses, improving its ability to generalize to new, similar tasks.
- **Prompt templates**: This technique involves creating structured templates that can be filled in with specific information or variables to generate prompts dynamically.


### 3.3: Describe the training and fine-tuning process for foundation models
Objectives:
- Describe the key elements of training a foundation model (for example,
pre-training, fine-tuning, continuous pre-training).
- Define methods for fine-tuning a foundation model (for example,
instruction tuning, adapting models for specific domains, transfer learning,
continuous pre-training).
- Describe how to prepare data to fine-tune a foundation model (for
example, data curation, governance, size, labeling, representativeness,
reinforcement learning from human feedback [RLHF]). 

#### Describe the key elements of training a foundation model 
- **Pre-training**: The initial phase where a foundation model is trained on a large and diverse dataset to learn general patterns and representations.
- **Fine-tuning**: The process of adapting a pre-trained foundation model to a specific task or domain by training it on a smaller, task-specific dataset.
- **Continuous pre-training**: An ongoing process where a foundation model is periodically updated with new data to maintain its relevance and performance.

### 3.4: Describe methods to evaluate foundation model performance
Objectives:
- Understand approaches to evaluate foundation model performance (for
example, human evaluation, benchmark datasets).
- Identify relevant metrics to assess foundation model performance (for
example, Recall-Oriented Understudy for Gisting Evaluation [ROUGE],
Bilingual Evaluation Understudy [BLEU], BERTScore).
- Determine whether a foundation model effectively meets business
objectives (for example, productivity, user engagement, task engineering). 

## üîó Related Domains

- [Domain 4: Guidelines for Responsible AI](domain-4-guidelines-responsible-ai.md) *(Coming Soon)*
- [Domain 5: Security, Compliance, and Governance](domain-5-security-compliance-governance.md) *(Coming Soon)*

---

**üìù Note**: This study guide is continuously updated. Check back regularly for new content and improvements!

[![Back to Main](https://img.shields.io/badge/‚Üê-Back%20to%20Main-blue?style=flat)](README.md)